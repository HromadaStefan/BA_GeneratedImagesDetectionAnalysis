{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920f8094-ceaa-44dd-8e73-813797492802",
   "metadata": {},
   "source": [
    "# Generierung der Bilder\n",
    "\n",
    "Zum generieren der Bilder wurde StableDiffusionXL verwendet. Dies ist ein bereits vorgefertigtes Modell zur generierung von Bilder. Dieses Modell ist zur Zeit eines der meist-verwendetsten Modelle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d8b68-d053-4f57-b149-7b6e3dfcb4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from diffusers import DiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70b57a7-66f5-4a6d-8f65-8a72679fe705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9f983b99834111a48ede42f0740d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialisiere CLIP und Diffusion-Modell\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "diffusion_model = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835a3a9-ca78-4e3f-80f3-f51b0a692439",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = './images/car/real/'\n",
    "target_dir = './images/car/fake_ImgToImg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd1fad-a49e-45ca-b64e-9b1148e283ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle den Zielordner, falls er nicht existiert\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e508e-2c16-4ea8-a241-b38c7145555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_crop(image, target_size=(256, 256)):\n",
    "    width, height = img.size\n",
    "    # kleineren Wert ermitteln, um das Bild nicht zu verzerren aber auch gleichzeitig so wenig wie möglich an Info zu verlieren \n",
    "    new_size = min(width, height)\n",
    "    \n",
    "    left = (width - new_size) / 2\n",
    "    top = (height - new_size) / 2\n",
    "    right = (width + new_size) / 2\n",
    "    bottom = (height + new_size) / 2\n",
    "    \n",
    "    # Bild croppen und resizen \n",
    "    img_cropped = img.crop((left, top, right, bottom))\n",
    "    img_resized = img_cropped.resize(target_size, Image.LANCZOS)\n",
    "    \n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69a980-83e8-40dc-bbeb-5bb65bdd5d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere Prompts für die Bildbeschreibung\n",
    "prompts = [\n",
    "    \"new car\",\n",
    "    \"old car\",\n",
    "]\n",
    "\n",
    "# Durchlaufe alle Dateien im Quellordner\n",
    "for filename in os.listdir(source_dir):\n",
    "    file_path = os.path.join(source_dir, filename)\n",
    "    \n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        init_image = Image.open(file_path)\n",
    "        init_image = resize_and_crop(init_image)\n",
    "\n",
    "        # Verwende CLIP, um einen beschreibenden Prompt für das Bild zu generieren\n",
    "        inputs = clip_processor(text=prompts, images=init_image, return_tensors=\"pt\")\n",
    "        outputs = clip_model(**inputs)\n",
    "        logits_per_image = outputs.logits_per_image\n",
    "        probs = logits_per_image.softmax(dim=1)\n",
    "        best_prompt_index = probs.argmax()\n",
    "        prompt_with_label = prompts[best_prompt_index]\n",
    "\n",
    "        # Verwende den beschreibenden Prompt für die Bildgenerierung mit dem Diffusion-Modell\n",
    "        generated_image = diffusion_model(prompt_with_label, image=init_image, strength=0.5, guidance_scale=8).images[0]\n",
    "\n",
    "        # Speichere das generierte Bild\n",
    "        save_path = os.path.join(target_dir, 'generated_' + prompt_with_label.replace(\" \", \"_\") + filename)\n",
    "        generated_image.save(save_path)\n",
    "\n",
    "        print(f\"Bild generiert und gespeichert als: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
